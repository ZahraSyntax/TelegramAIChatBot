import os
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

load_dotenv()

TELEGRAM_API_TOKEN = os.getenv('TELEGRAM_API_TOKEN')
AVAL_AI_API_TOKEN = os.getenv('AVAL_AI_API_TOKEN')

llm = ChatOpenAI(
    model="gpt-3.5-turbo",
    base_url="https://api.avalai.ir/v1",
    api_key=AVAL_AI_API_TOKEN
)

def query_langchain_ai(message: str) -> str:
    try:
        response = llm.invoke(message)
        if hasattr(response, "content"):
            return response.content
        else:
            return str(response)
    except Exception as e:
        return f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ø³Ø±ÙˆØ± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ: {str(e)}"

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.message.reply_text(
        "Ø³Ù„Ø§Ù…! Ù…Ù† Ø±Ø¨Ø§Øª Ú†Øª Ø¬ÛŒâ€ŒÙ¾ÛŒâ€ŒØªÛŒ Ù‡Ø³ØªÙ….\n"
        "Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø¨Ø®Ø´ÛŒ Ø§Ø² ÛŒÚ© Ù¾Ø±ÙˆÚ˜Ù‡ Ø¯Ø§Ù†Ø´Ø¬ÙˆÛŒÛŒ ØªÙˆØ³Ø¹Ù‡ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.\n"
        "Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ØŒ Ù¾ÛŒØ§Ù… Ø®ÙˆØ¯ Ø±Ø§ ØªØ§ÛŒÙ¾ Ú©Ù†ÛŒØ¯ Ùˆ Ù…Ù† Ø³Ø¹ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ù… Ø¨Ù‡ Ø¨Ù‡ØªØ±ÛŒÙ† Ø´Ú©Ù„ Ù…Ù…Ú©Ù† Ø¨Ù‡ Ø´Ù…Ø§ Ù¾Ø§Ø³Ø® Ø¯Ù‡Ù…. ðŸ˜Š"
    )

async def chat(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user_message = update.message.text
    response = query_langchain_ai(user_message)
    await update.message.reply_text(response)

def main():
    application = ApplicationBuilder().token(TELEGRAM_API_TOKEN).build()

    application.add_handler(CommandHandler('start', start))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, chat))

    application.run_polling()

if __name__ == '__main__':
    main()